---
sidebar: sidebar 
permalink: xcp/xcp-bp-deployment-steps.html 
keywords: deployment, solution components, linux server, windows server aff a800, ha 
summary: このセクションでは、データ転送用のNetApp XCP の導入手順について説明します。 
---
= 導入手順
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
このセクションでは、データ転送用のNetApp XCP の導入手順について説明します。



== テストベッドの詳細

次の表は、この展開とパフォーマンス検証に使用されたテスト ベッドの詳細を示しています。

|===
| ソリューションコンポーネント | 詳細 


| XCP バージョン 1.7  a| 
* 1 台の Linux サーバー - Linux (RHEL 7.9 または RHEL 8)
* Windows サーバー 1 台 – Windows Server 2019 標準




| ソースボリューム用のNetApp AFFストレージアレイHAペア  a| 
* AFF8080
* NetApp ONTAP 9
* NFSプロトコル




| 宛先ボリューム用のNetApp AFFストレージアレイHAペア  a| 
* AFF A800用
* ONTAP 9
* NFSプロトコル




| 富士通 PRIMERGY RX2540 サーバ | それぞれに以下の機能が搭載されています: * 48個のCPU * Intel Xeon * 256GBの物理メモリ * 10GbEデュアルポート 


| ネットワーク | 10GbE 
|===


== 展開手順 - NAS

データ転送用にNetApp XCP を導入するには、まず宛先の場所に XCP ソフトウェアをインストールしてアクティブ化します。詳細は、 https://mysupport.netapp.com/documentation/productlibrary/index.html?productID=63064["NetApp XCP ユーザーガイド"^] 。これには、次の手順を実行します。

. セクションに記載されている前提条件を満たすlink:xcp-bp-netapp-xcp-overview.html#prerequisites-for-xcp["XCP の前提条件。"]
. XCPソフトウェアを以下からダウンロードしてください。 https://mysupport.netapp.com/site/products/all/details/netapp-xcp/downloads-tab["NetApp XCP（ダウンロード）ページ"^] 。
. ダウンロードした XCP tar ファイルを XCP サーバーにコピーします。
+
....
# scp Documents/OneDrive\ -\ NetApp\ Inc/XCP/software/1.6.1/NETAPP_XCP_1.6.1.tgz mailto:root@10.63.150.53:/usr/src
....
. tar ファイルを解凍します。
+
....
[root@mastr-53 src]# tar -zxvf NETAPP_XCP_1.6.1.tgz
....
. ライセンスをダウンロードするには https://xcp.netapp.com/license/xcp.xwic%20["https://xcp.netapp.com/license/xcp.xwic"^]XCP サーバーにコピーします。
. ライセンスを有効化します。
+
....
[root@mastr-53 linux]# ./xcp activate
[root@mastr-53 src]# cp license /opt/NetApp/xFiles/xcp/license
[root@mastr-53 src]# cd /usr/src/xcp/linux/
[root@mastr-53 linux]# ./xcp activate
....
. ソース NFS ポートと宛先 NFS サーバーを見つけます。デフォルト ポートは2049です。
+
....
[root@mastr-53 ~]# rpcinfo -p 10.63.150.213
[root@mastr-53 ~]# rpcinfo -p 10.63.150.63
....
. NFS 接続を確認してください。  NFS サーバー ポートに telnet を使用して、NFS サーバー (ソースと宛先の両方) を確認します。
+
....
[root@mastr-53 ~]# telnet 10.63.150.127 2049
[root@mastr-53 ~]# telnet 10.63.150.63 2049
....
. カタログを構成します。
+
.. NFS ボリュームを作成し、XCP カタログの NFS をエクスポートします。  XCP カタログにオペレーティング システムの NFS エクスポートを活用することもできます。
+
....
A800-Node1-2::> volume create -vserver Hadoop_SVM -volume xcpcatalog -aggregate aggr_Hadoop_1 -size 50GB -state online -junction-path /xcpcatalog -policy default -unix-permissions ---rwxr-xr-x -type RW -snapshot-policy default -foreground true
A800-Node1-2::> volume mount -vserver Hadoop_SVM -volume xcpcatalog_vol -junction-path /xcpcatalog
....
.. NFS エクスポートを確認します。
+
....
[root@mastr-53 ~]# showmount -e 10.63.150.63 | grep xcpca
/xcpcatalog (everyone)
....
.. アップデート `xcp.ini`。
+
....
[root@mastr-53 ~]# cat /opt/NetApp/xFiles/xcp/xcp.ini
# Sample xcp config
[xcp]
catalog = 10.63.150.64:/xcpcatalog

[root@mastr-53 ~]#
....


. ソースNASエクスポートを検索するには、 `xcp show` 。探す：
+
....
== NFS Exports ==
== Attributes of NFS Exports ==
....
+
....
[root@mastr-53 linux]# ./xcp show 10.63.150.127
== NFS Exports ==
<check here>
== Attributes of NFS Exports ==
<check here>
....
. (オプション) ソース NAS データをスキャンします。
+
....
[root@mastr-53 linux]# ./xcp scan -newid xcpscantest4 -stats 10.63.150.127:/xcpsrc_vol
....
+
ソース NAS データをスキャンすると、データ レイアウトを理解し、移行に関する潜在的な問題を見つけるのに役立ちます。  XCP スキャン操作時間は、ファイル数とディレクトリの深さに比例します。  NAS データに精通している場合は、この手順をスキップできます。

. 作成されたレポートを確認する `xcp scan`。読み取り不可能なフォルダーや読み取り不可能なファイルを主に検索します。
+
....
[root@mastr-53 linux]# mount 10.63.150.64:/xcpcatalog  /xcpcatalog
base) nkarthik-mac-0:~ karthikeyannagalingam$ scp -r root@10.63.150.53:/xcpcatalog/catalog/indexes/xcpscantest4 Documents/OneDrive\ -\ NetApp\ Inc/XCP/customers/reports/
....
. (オプション) inode を変更します。  inode の数を表示し、カタログと宛先ボリュームの両方で移行またはコピーするファイルの数に基づいて数を変更します (必要な場合)。
+
....
A800-Node1-2::> volume show -volume xcpcatalog -fields files,files-used
A800-Node1-2::> volume show -volume xcpdest -fields files,files-used
A800-Node1-2::> volume modify -volume xcpcatalog -vserver A800-Node1_vs1 -files 2000000
Volume modify successful on volume xcpcatalog of Vserver A800-Node1_vs1.

A800-Node1-2::> volume show -volume xcpcatalog -fields files,files-used
....
. 宛先ボリュームをスキャンします。
+
....
[root@mastr-53 linux]# ./xcp scan -stats 10.63.150.63:/xcpdest
....
. ソースボリュームと宛先ボリュームのスペースを確認します。
+
....
[root@mastr-53 ~]# df -h /xcpsrc_vol
[root@mastr-53 ~]# df -h /xcpdest/
....
. データをソースから宛先にコピーするには、 `xcp copy`概要を確認します。
+
....
[root@mastr-53 linux]# ./xcp copy -newid create_Sep091599198212 10.63.150.127:/xcpsrc_vol 10.63.150.63:/xcpdest
<command inprogress results removed>
Xcp command : xcp copy -newid create_Sep091599198212 -parallel 23 10.63.150.127:/xcpsrc_vol 10.63.150.63:/xcpdest
Stats       : 9.07M scanned, 9.07M copied, 118 linked, 9.07M indexed, 173 giants
Speed       : 1.57 TiB in (412 MiB/s), 1.50 TiB out (392 MiB/s)
Total Time  : 1h6m.
STATUS      : PASSED
[root@mastr-53 linux]#
....
+

NOTE: デフォルトでは、XCP はデータをコピーするために 7 つの並列プロセスを作成します。これは調整可能です。

+

NOTE: NetApp、ソース ボリュームを読み取り専用にすることを推奨しています。リアルタイムでは、ソース ボリュームはライブのアクティブなファイル システムです。その `xcp copy`NetApp XCP はアプリケーションによって継続的に変更されるライブ ソースをサポートしていないため、操作が失敗する可能性があります。

+
Linux の場合、XCP Linux がカタログ作成を実行するため、XCP にはインデックス ID が必要です。

. (オプション) 宛先NetAppボリューム上の inode を確認します。
+
....
A800-Node1-2::> volume show -volume xcpdest -fields files,files-used
vserver        volume  files    files-used
-------------- ------- -------- ----------
A800-Node1_vs1 xcpdest 21251126 15039685

A800-Node1-2::>
....
. 増分更新を実行するには、 `xcp sync` 。
+
....
[root@mastr-53 linux]# ./xcp sync -id create_Sep091599198212
Xcp command : xcp sync -id create_Sep091599198212
Stats       : 9.07M reviewed, 9.07M checked at source, no changes, 9.07M reindexed
Speed       : 1.73 GiB in (8.40 MiB/s), 1.98 GiB out (9.59 MiB/s)
Total Time  : 3m31s.
STATUS      : PASSED
....
+
この文書では、リアルタイムでシミュレートするために、ソースデータ内の100万のファイルの名前を変更し、更新されたファイルを次の方法で宛先にコピーしました。 `xcp sync` 。  Windows の場合、XCP にはソース パスと宛先パスの両方が必要です。

. データ転送を検証します。ソースと宛先が同じデータを持っているかどうかは、次の方法で検証できます。 `xcp verify` 。
+
....
Xcp command : xcp verify 10.63.150.127:/xcpsrc_vol 10.63.150.63:/xcpdest
Stats       : 9.07M scanned, 9.07M indexed, 173 giants, 100% found (6.01M have data), 6.01M compared, 100% verified (data, attrs, mods)
Speed       : 3.13 TiB in (509 MiB/s), 11.1 GiB out (1.76 MiB/s)
Total Time  : 1h47m.
STATUS      : PASSED
....


XCPドキュメントでは、複数のオプション（例付き）が提供されています。 `scan` 、 `copy` 、 `sync` 、 そして `verify`操作。詳細については、 https://mysupport.netapp.com/documentation/productlibrary/index.html?productID=63064["NetApp XCP ユーザーガイド"^] 。


NOTE: Windows ユーザーは、アクセス制御リスト (ACL) を使用してデータをコピーする必要があります。 NetAppはコマンドの使用を推奨しています `xcp copy -acl -fallbackuser\<username> -fallbackgroup\<username or groupname> <source> <destination>`。パフォーマンスを最大限に高めるには、ACL 付きの SMB データと NFS と SMB の両方でアクセス可能なデータを持つソース ボリュームを考慮すると、ターゲットは NTFS ボリュームである必要があります。  XCP（NFS版）を使用してLinuxサーバーからデータをコピーし、XCP（SMB版）同期を実行します。 `-acl`そして `-nodata`Windows サーバーのオプションを使用して、ACL をソース データからターゲット SMB データにコピーします。

詳細な手順については、 https://helpcenter.netwrix.com/NA/Configure_IT_Infrastructure/Accounts/DCA_Manage_Auditing_Security_Log.html["「監査とセキュリティログの管理」ポリシーの構成"^] 。



== 導入手順 - HDFS/MapRFS データの移行

このセクションでは、HDFS/MapRFS から NFS へ、またはその逆にデータを移行する、Hadoop Filesystem Data Transfer to NAS という新しい XCP 機能について説明します。



=== 前提条件

MapRFS/HDFS 機能の場合、非ルート ユーザー環境で次の手順を実行する必要があります。通常、非ルート ユーザーは、hdfs、mapr、または HDFS および MapRFS ファイルシステムに変更を加える権限を持つユーザーです。

. CLIまたはユーザーの.bashrcファイルで、CLASSPATH、HADOOP_HOME、NHDFS_LIBJVM_PATH、LB_LIBRARY_PATH、およびNHDFS_LIBHDFS_PATH変数を次のように設定します。 `xcp`指示。
+
** NHDFS_LIBHDFS_PATH は libhdfs.so ファイルを指します。このファイルは、Hadoop ディストリビューションの一部として HDFS/MapRFS ファイルおよびファイルシステムを対話および操作するための HDFS API を提供します。
** NHDFS_LIBJVM_PATH は libjvm.so ファイルを指します。これは、jre の場所にある共有 JAVA 仮想マシン ライブラリです。
** CLASSPATH は、(Hadoop classpath –glob) 値を使用してすべての jar ファイルを指します。
** LD_LIBRARY_PATH は、Hadoop ネイティブ ライブラリ フォルダーの場所を指します。
+
Cloudera クラスターに基づく次のサンプルを参照してください。

+
[listing]
----
export CLASSPATH=$(hadoop classpath --glob)
export LD_LIBRARY_PATH=/usr/java/jdk1.8.0_181-cloudera/jre/lib/amd64/server/
export HADOOP_HOME=/opt/cloudera/parcels/CDH-6.3.4-1.cdh6.3.4.p0.6751098/
#export HADOOP_HOME=/opt/cloudera/parcels/CDH/
export NHDFS_LIBJVM_PATH=/usr/java/jdk1.8.0_181-cloudera/jre/lib/amd64/server/libjvm.so
export NHDFS_LIBHDFS_PATH=$HADOOP_HOME/lib64/libhdfs.so
----
+
このリリースでは、XCP スキャン、コピー、検証操作と、HDFS から NFS へのデータ移行をサポートしています。データ レイク クラスターの単一ワーカー ノードおよび複数のワーカー ノードからデータを転送できます。  1.8 リリースでは、ルート ユーザーと非ルート ユーザーがデータ移行を実行できます。







=== 導入手順 - 非ルートユーザーがHDFS/MaprFSデータをNetApp NFSに移行する

. 展開手順セクションの 1 ～ 9 の手順と同じ手順に従います。
. 次の例では、ユーザーは HDFS から NFS にデータを移行します。
+
.. フォルダとファイルを作成する（ `hadoop fs -copyFromLocal` ) を HDFS にアップロードします。
+
[listing]
----
[root@n138 ~]# su - tester -c 'hadoop fs -mkdir /tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src'
[root@n138 ~]# su - tester -c 'hadoop fs -ls -d  /tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src'
drwxr-xr-x   - tester supergroup          0 2021-11-16 16:52 /tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src
[root@n138 ~]# su - tester -c "echo 'testfile hdfs' > /tmp/a_hdfs.txt"
[root@n138 ~]# su - tester -c "echo 'testfile hdfs 2' > /tmp/b_hdfs.txt"
[root@n138 ~]# ls -ltrah /tmp/*_hdfs.txt
-rw-rw-r-- 1 tester tester 14 Nov 16 17:00 /tmp/a_hdfs.txt
-rw-rw-r-- 1 tester tester 16 Nov 16 17:00 /tmp/b_hdfs.txt
[root@n138 ~]# su - tester -c 'hadoop fs -copyFromLocal /tmp/*_hdfs.txt hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src'
[root@n138 ~]#
----
.. HDFS フォルダーの権限を確認します。
+
[listing]
----
[root@n138 ~]# su - tester -c 'hadoop fs -ls hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src'
Found 2 items
-rw-r--r--   3 tester supergroup         14 2021-11-16 17:01 hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src/a_hdfs.txt
-rw-r--r--   3 tester supergroup         16 2021-11-16 17:01 hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src/b_hdfs.txt
----
.. NFS にフォルダーを作成し、権限を確認します。
+
[listing]
----
[root@n138 ~]# su - tester -c 'mkdir /xcpsrc_vol/mohankarthiknfs_dest'
[root@n138 ~]# su - tester -c 'ls -l /xcpsrc_vol/mohankarthiknfs_dest'
total 0
[root@n138 ~]# su - tester -c 'ls -d /xcpsrc_vol/mohankarthiknfs_dest'
/xcpsrc_vol/mohankarthiknfs_dest
[root@n138 ~]# su - tester -c 'ls -ld /xcpsrc_vol/mohankarthiknfs_dest'
drwxrwxr-x 2 tester tester 4096 Nov 16 14:32 /xcpsrc_vol/mohankarthiknfs_dest
[root@n138 ~]#
----
.. XCP を使用して HDFS から NFS にファイルをコピーし、権限を確認します。
+
[listing]
----
[root@n138 ~]# su - tester -c '/usr/src/hdfs_nightly/xcp/linux/xcp copy -chown hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src/ 10.63.150.126:/xcpsrc_vol/mohankarthiknfs_dest'
XCP Nightly_dev; (c) 2021 NetApp, Inc.; Licensed to Karthikeyan Nagalingam [NetApp Inc] until Wed Feb  9 13:38:12 2022

xcp: WARNING: No index name has been specified, creating one with name: autoname_copy_2021-11-16_17.04.03.652673

Xcp command : xcp copy -chown hdfs:///tmp/testerfolder_src/util-linux-2.23.2/mohankarthikhdfs_src/ 10.63.150.126:/xcpsrc_vol/mohankarthiknfs_dest
Stats       : 3 scanned, 2 copied, 3 indexed
Speed       : 3.44 KiB in (650/s), 80.2 KiB out (14.8 KiB/s)
Total Time  : 5s.
STATUS      : PASSED
[root@n138 ~]# su - tester -c 'ls -l /xcpsrc_vol/mohankarthiknfs_dest'
total 0
-rw-r--r-- 1 tester supergroup 14 Nov 16 17:01 a_hdfs.txt
-rw-r--r-- 1 tester supergroup 16 Nov 16 17:01 b_hdfs.txt
[root@n138 ~]# su - tester -c 'ls -ld /xcpsrc_vol/mohankarthiknfs_dest'
drwxr-xr-x 2 tester supergroup 4096 Nov 16 17:01 /xcpsrc_vol/mohankarthiknfs_dest
[root@n138 ~]#
----



